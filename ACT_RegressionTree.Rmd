---
title: "Untitled"
author: "Felicia Zhang"
date: '2018-12-01'
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2) 
library(zoo)
library(reshape)
library(plyr)
library(dplyr)
library(scales) 
library(data.table)
library(signal)
library(matrixStats)
library(lme4)
library(arm)
library(broom)
library(tidyr)
library(wesanderson)
library(car)
library(lmerTest)
library(rpart)
library(rpart.plot)
library(partykit)
library(shiny)
library(knitr)

#Import data
mp <- read.csv("~/Documents/Felicia Zhang/Felicia/Princeton/ConsultingClub/Mindprint/Mindprint_ScaledScores_010819.csv")

# Label students who received extra time: 2507 (don't have data), 2421, 4499, 6150, 517, 2010, 2948, 6171, 5866, 4967, 2720, 1872, 6808
mp$ExtraTime <- 0

mp$ExtraTime[mp$customer_id==2421] <- 1
mp$ExtraTime[mp$customer_id==4499] <- 1
mp$ExtraTime[mp$customer_id==6150] <- 1
mp$ExtraTime[mp$customer_id==517] <- 1
mp$ExtraTime[mp$customer_id==2010] <- 1
mp$ExtraTime[mp$customer_id==2948] <- 1
mp$ExtraTime[mp$customer_id==6171] <- 1
mp$ExtraTime[mp$customer_id==5866] <- 1
mp$ExtraTime[mp$customer_id==4967] <- 1
mp$ExtraTime[mp$customer_id==2720] <- 1
mp$ExtraTime[mp$customer_id==1872] <- 1
mp$ExtraTime[mp$customer_id==6808] <- 1
mp$ExtraTime[mp$customer_id==8568] <- 1
mp$ExtraTime[mp$customer_id==10266] <- 1
mp$ExtraTime[mp$customer_id==8409] <- 1

length(which(mp$ExtraTime==1))

# Replace outlier Mindprint scores (accuracy scores with < -2 with -2)
# 1901: WM_Az, 5143: ATT_Az, 1902: ATT_Az, 6381: ATT_Az

mp$WM_Az[mp$customer_id==1901] <- -2
mp$ATT_Az[mp$customer_id==5143] <- -2
mp$ATT_Az[mp$customer_id==1902] <- -2
mp$ATT_Az[mp$customer_id==6381] <- -2

# Remove students that having missing ACT subject scores

mp <- mp[!is.na(mp$EngScaledScore),]
mp <- mp[!is.na(mp$MathScaledScore),]
mp <- mp[!is.na(mp$ScienceScaledScore),]
mp <- mp[!is.na(mp$ReadingScaledScore),]

###### Prepare DF ###### 
# drop processing speed
mp$PROCESSING_SPEED_Sz <- NULL

# drop students who received extra time
mp <- subset(mp, ExtraTime==0)

###### Prepare predictor DF ###### 

# drop processing speed
mindprint <- mp[,c(1:35)]
mindprint$customer_id <- NULL
mindprint$age <- NULL
mindprint$SM_SCORE <- NULL
mindprint$VMEM_SCORE <- NULL
mindprint$ABF_SCORE <- NULL
mindprint$LAN_SCORE <- NULL
mindprint$NVR_SCORE <- NULL
mindprint$WM_SCORE <- NULL
mindprint$ATT_SCORE <- NULL
mindprint$SMEM_SCORE <- NULL

head(mindprint)

write.csv(mp, "ACT_MP.csv", row.names=TRUE) #save to computer
``` 

Reading
```{r}
y <- mp$ReadingScaledScore

finalDF <- cbind(mindprint, y)

# 1. grow tree 
tree <- rpart(y~., method="anova", minsplit=20, minbucket=20, maxdepth=3, data=finalDF)

#printcp(tree) # display the results 
#plotcp(tree) # visualize cross-validation results 

# 2. find best cp
#bestcp <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]

# 3. Prune the tree using the best cp.
#tree.pruned <- prune(tree, cp = bestcp)

# Plot
plot(as.party(tree), main="Regression Tree for ACT Reading")
#box plots of the outcome that we are trying to predict.

# calculate SD and CI
stats <- aggregate(finalDF$y, list(tree$where), sd)
names(stats)[1] <- "node"
names(stats)[2] <- "sd"
stats2 <- aggregate(finalDF$y, list(tree$where), mean)
names(stats2)[2] <- "mean"
stats$mean <- stats2$mean
stats$onesd_lower <- stats$mean - stats$sd
stats$onesd_upper <- stats$mean + stats$sd
stats$twosd_lower <- stats$mean - (2*stats$sd)
stats$twosd_upper <- stats$mean + (2*stats$sd)
  
kable(stats, format = "markdown", align = 'c', row.names=F)

# IDENTIFY OUTLIERS
#node5
foo2 <- subset(mp, LAN_efficiency < 0.844 & NVR_efficiency < 0.157 & WM_Sz >= -0.279)
foo2$customer_id[which(foo2$ReadingScaledScore > mean(foo2$ReadingScaledScore) + (2*sd(foo2$ReadingScaledScore)))] 

#node7
foo3 <- subset(mp, LAN_efficiency < 0.844 & NVR_efficiency >= 0.157 & LAN_Sz < 0.265)
foo3$customer_id[which(foo3$ReadingScaledScore > mean(foo3$ReadingScaledScore) + (2*sd(foo3$ReadingScaledScore)))] 

#node3
foo <- subset(mp, LAN_efficiency >= 0.844)
foo$customer_id[which(foo$ReadingScaledScore < mean(foo$ReadingScaledScore) - (2*sd(foo$ReadingScaledScore)))]
```

English
```{r}
y <- mp$EngScaledScore

finalDF <- cbind(mindprint, y)

# 1. grow tree 
tree <- rpart(y~., method="anova", minsplit=20, minbucket=20, maxdepth=3, data=finalDF)
# 
# printcp(tree) # display the results 
# plotcp(tree) # visualize cross-validation results 
# 
# # 2. find best cp
# bestcp <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
# 
# # 3. Prune the tree using the best cp.
# tree.pruned <- prune(tree, cp = bestcp)

# Plot (w/box plots)
plot(as.party(tree), main="Regression Tree for ACT English") 

# calculate SD and CI
stats <- aggregate(finalDF$y, list(tree$where), sd)
names(stats)[1] <- "node"
names(stats)[2] <- "sd"
stats2 <- aggregate(finalDF$y, list(tree$where), mean)
names(stats2)[2] <- "mean"
stats$mean <- stats2$mean
stats$onesd_lower <- stats$mean - stats$sd
stats$onesd_upper <- stats$mean + stats$sd
stats$twosd_lower <- stats$mean - (2*stats$sd)
stats$twosd_upper <- stats$mean + (2*stats$sd)

kable(stats, format = "markdown", align = 'c', row.names=F)

# IDENTIFY OUTLIERS
#node7
foo3 <- subset(mp, LAN_efficiency >= 0.94)
foo3$customer_id[which(foo3$EngScaledScore < mean(foo3$EngScaledScore) - (2*sd(foo3$EngScaledScore)))] #none
```

Math
```{r}
y <- mp$MathScaledScore

finalDF <- cbind(mindprint, y)

# 1. grow tree 
tree <- rpart(y~., method="anova", minsplit=20, minbucket=20, maxdepth=2, data=finalDF)

# printcp(tree) # display the results 
# plotcp(tree) # visualize cross-validation results 
# 
# # 2. find best cp
# bestcp <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
# 
# # 3. Prune the tree using the best cp.
# tree.pruned <- prune(tree, cp = bestcp)

# Plot
plot(as.party(tree), main="Regression Tree for ACT Math")

# calculate SD and CI
stats <- aggregate(finalDF$y, list(tree$where), sd)
names(stats)[1] <- "node"
names(stats)[2] <- "sd"
stats2 <- aggregate(finalDF$y, list(tree$where), mean)
names(stats2)[2] <- "mean"
stats$mean <- stats2$mean
stats$onesd_lower <- stats$mean - stats$sd
stats$onesd_upper <- stats$mean + stats$sd
stats$twosd_lower <- stats$mean - (2*stats$sd)
stats$twosd_upper <- stats$mean + (2*stats$sd)

kable(stats, format = "markdown", align = 'c', row.names=F)

# IDENTIFY OUTLIERS
#node4
foo3 <- subset(mp, NVR_efficiency < 0.302 & LAN_Az < 0.418 & VMEM_Az < 0.459)
foo3$customer_id[which(foo3$MathScaledScore > mean(foo3$MathScaledScore) + (2*sd(foo3$MathScaledScore)))] 

#node12
foo2 <- subset(mp, NVR_efficiency >= 0.302 & LAN_Sz >= 0.27 & SPA_Sz >= -0.119)
foo2$customer_id[which(foo2$MathScaledScore < mean(foo2$MathScaledScore) - (2*sd(foo2$MathScaledScore)))] 
```

Science
```{r}
y <- mp$ScienceScaledScore

# remove SM_Sz for science
mindprint$SM_Sz <- NULL

finalDF <- cbind(mindprint, y)

# 1. grow tree 
tree <- rpart(y~., method="anova", minsplit=20, minbucket=20, maxdepth=3, data=finalDF)

# printcp(tree) # display the results 
# plotcp(tree) # visualize cross-validation results 
# 
# # 2. find best cp
# bestcp <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
# 
# # 3. Prune the tree using the best cp.
# tree.pruned <- prune(tree, cp = bestcp)

# Plot
plot(as.party(tree), main="Regression Tree for ACT Science")
#box plots of the outcome that we are trying to predict.

# calculate SD and CI
stats <- aggregate(finalDF$y, list(tree$where), sd)
names(stats)[1] <- "node"
names(stats)[2] <- "sd"
stats2 <- aggregate(finalDF$y, list(tree$where), mean)
names(stats2)[2] <- "mean"
stats$mean <- stats2$mean
stats$onesd_lower <- stats$mean - stats$sd
stats$onesd_upper <- stats$mean + stats$sd
stats$twosd_lower <- stats$mean - (2*stats$sd)
stats$twosd_upper <- stats$mean + (2*stats$sd)

kable(stats, format = "markdown", align = 'c', row.names=F)

# IDENTIFY OUTLIERS
#node3
foo3 <- subset(mp, LAN_efficiency < 0.93 & LAN_efficiency < -0.305)
foo3$customer_id[which(foo3$ScienceScaledScore < mean(foo3$ScienceScaledScore) - (2*sd(foo3$ScienceScaledScore)))] #none

#node5
foo3 <- subset(mp, LAN_efficiency < 0.93 & LAN_efficiency >= -0.305 & NVR_Az < 1.264)
foo3$customer_id[which(foo3$ScienceScaledScore > mean(foo3$ScienceScaledScore) + (2*sd(foo3$ScienceScaledScore)))] 

#node5
foo3 <- subset(mp, LAN_efficiency < 0.93 & LAN_efficiency >= -0.305 & NVR_Az < 1.264)
foo3$customer_id[which(foo3$ScienceScaledScore < mean(foo3$ScienceScaledScore) - (2*sd(foo3$ScienceScaledScore)))] 
```
