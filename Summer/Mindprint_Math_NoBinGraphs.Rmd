---
title: "Mindprint - Math"
author: "Felicia Zhang"
date: '2018-08-01'
output: pdf_document
toc: yes
toc_depth: 2
fontsize: 12pt
fig_height: 5
fig_width: 7
---

```{r setup, include=FALSE, warning=FALSE}
library(ggplot2) 
library(zoo)
library(reshape)
library(plyr)
library(dplyr)
library(scales) 
library(data.table)
library(signal)
library(matrixStats)
library(lme4)
library(arm)
library(broom)
library(tidyr)
library(wesanderson)
library(readxl)    
library(extrafont)

## 1. Load ACT/SAT data

#LOAD MULTIPLE EXCEL SHEETS INTO SEPARATE DFS

#get names of sheets
sheets <- readxl::excel_sheets("~/Documents/Felicia Zhang/Felicia/Princeton/ConsultingClub/Mindprint/Math.xlsx")

#load in excel data as 1 big file
lst <- lapply(sheets, function(sheet) 
  readxl::read_excel("~/Documents/Felicia Zhang/Felicia/Princeton/ConsultingClub/Mindprint/Math.xlsx", sheet = sheet)
)

#prepare names
names(lst) <- sheets

#turn it into DF
list2env(lst, envir = .GlobalEnv)

#difference between 70C, 72C, Combo v2.4: three different tests based on where we had sufficient student data, noting the one called the Combo is a mixture of SAT and ACT questions.

#0 = incorrect, 1 = correct, 2 = skip

## 2. Load mindprint data
mindprintdata <- read.csv("~/Documents/Felicia Zhang/Felicia/Princeton/ConsultingClub/Mindprint/mindprint_data.csv", header=T)
```

```{r, echo=FALSE, warning=FALSE, include=FALSE}
## SET UP DF
names(`70C`)[2:61] = 1:60
names(`72C`)[2:61] = 1:60

# Mindprint subjects
subs <- unique(mindprintdata$student_id)

# duplicates = subID 441, 8826, 4573, 

# Find matching subjects in 70C
z <- which(`70C`$Question=="student_id")
zz <- length(`70C`$Question)
foo <- `70C`[(z+1):zz,]
foo[] <- lapply(foo, function(x) as.numeric(as.character(x)))
colnames(foo)[1] <- "student_id"

foofinal1 <- merge(mindprintdata, foo)

# Find matching subjects in 72C
z <- which(`72C`$Question=="student_id")
zz <- length(`72C`$Question)
foo <- `72C`[(z+1):zz,]
foo[] <- lapply(foo, function(x) as.numeric(as.character(x)))
colnames(foo)[1] <- "student_id"

foofinal2 <- merge(mindprintdata, foo)

finalDF <- rbind(foofinal1,foofinal2)

# calculate ACT math score (total number of questions = 60)
finalDF$ACTmathraw <- rowSums(finalDF[43:102])
finalDF$ACTmathscore <- finalDF$ACTmathraw / 60

# remove missing data
finalDF2 <- na.omit(finalDF)
```

\newpage

# ACT Math (n = 61) | no binning
## Overall score 
### Verbal reasoning accuracy (no correlation)
```{r, echo=FALSE, warning=FALSE}

ggplot(finalDF2,aes(x=LAN_Az,y=ACTmathscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for verbal reasoning", y = "ACT math score (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(finalDF2$LAN_Az, finalDF2$ACTmathscore, method="pearson")  
```
\newpage

### Working memory efficiency (p = 0.049, r = 0.25)
##### Average of normed accuracy and speed scores for working memory.
```{r, echo=FALSE, warning=FALSE}

ggplot(finalDF2,aes(x=WM_EFFICIENCY,y=ACTmathscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Average of normed accuracy and speed scores for working memory", y = "ACT math score (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(finalDF2$WM_EFFICIENCY, finalDF2$ACTmathscore, method="pearson")    
```
\newpage

### Spatial perception accuracy (p = 0.011, r = 0.32)
```{r, echo=FALSE, warning=FALSE}

ggplot(finalDF2,aes(x=SPA_Az,y=ACTmathscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for spatial perception", y = "ACT math score (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(finalDF2$SPA_Az, finalDF2$ACTmathscore, method="pearson")  
```
\newpage

### Multi-variate analysis  
```{r, echo=FALSE, warning=FALSE}

overallmath_model <- lm(ACTmathscore ~ SPA_Az + WM_EFFICIENCY, data=finalDF2)  

summary(overallmath_model)

```
Spatial perception accuracy is a stronger predictor of overall math score compared to working memory efficiency, but WM efficiency is still important.

\newpage
```{r, echo=FALSE, warning=FALSE, include=FALSE}
## set up subsection DF

# figure out which subsection each question corresponded to
foo <- `70C`[c(1,2,3,4,20),]
subsection <- t(foo)
subsection <- data.frame(subsection)
subsection <- subsection[-1, ] 

colnames(subsection)[1] <- "test"
colnames(subsection)[2] <- "question"
colnames(subsection)[3] <- "section"
colnames(subsection)[4] <- "subsection"
colnames(subsection)[5] <- "difficulty"

EA <- subset(subsection, subsection=="EA")
GT <- subset(subsection, subsection=="GT")
AG <- subset(subsection, subsection=="AG")

EAnum <- unique(EA$question)
EAnum <- as.numeric(EAnum)
GTnum <- unique(GT$question)
GTnum <- as.numeric(GTnum)
AGnum <- unique(AG$question)
AGnum <- as.numeric(AGnum)

#all questions
questions <- finalDF2[,43:102]

#AG DF
AG_DF <- questions[,AGnum]
AG_DF$AGraw <- rowSums(AG_DF)
AG_DF$AGscore <- AG_DF$AGraw / length(AGnum)
AG_DF <- cbind(finalDF2[,1:42],AG_DF)

#EA DF
EA_DF <- questions[,EAnum]
EA_DF$EAraw <- rowSums(EA_DF)
EA_DF$EAscore <- EA_DF$EAraw / length(EAnum)
EA_DF <- cbind(finalDF2[,1:42],EA_DF)

#GT DF
GT_DF <- questions[,GTnum]
GT_DF$GTraw <- rowSums(GT_DF)
GT_DF$GTscore <- GT_DF$GTraw / length(GTnum)
GT_DF <- cbind(finalDF2[,1:42],GT_DF)
```

## EA/ Pre-Algebra/Elementary Algebra Subsection
### Visual motor speed (no correlation)
```{r, echo=FALSE, warning=FALSE}

ggplot(EA_DF,aes(x=SM_Sz,y=EAscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed score for visual motor speed", y = "Pre-Algebra/Elementary Algebra (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)
  
cor.test(EA_DF$SM_Sz, EA_DF$EAscore, method="pearson")
```
\newpage

### Spatial perception accuracy (p = 0.002, r = 0.39)
```{r, echo=FALSE, warning=FALSE}

ggplot(EA_DF,aes(x=SPA_Az,y=EAscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for spatial perception", y = "Pre-Algebra/Elementary Algebra (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(EA_DF$SPA_Az, EA_DF$EAscore, method="pearson")  
```
\newpage

## GT/ Plane Geometry/Trigonometry Subsection

### Abstract reasoning accuracy (no correlation)
```{r, echo=FALSE, warning=FALSE}

ggplot(GT_DF,aes(x=NVR_Az,y=GTscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for abstract reasoning", y = "Plane Geometry/Trigonometry (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(GT_DF$NVR_Az, GT_DF$GTscore, method="pearson")  
```
\newpage

### Spatial perception accuracy (p = 0.027, r = 0.28)
```{r, echo=FALSE, warning=FALSE}

ggplot(GT_DF,aes(x=SPA_Az,y=GTscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for spatial perception", y = "Plane Geometry/Trigonometry (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(GT_DF$SPA_Az, GT_DF$GTscore, method="pearson")  
```
\newpage

## AG/ Intermediate Algebra/Coordinate Geometry Subsection
### Working memory accuracy (p = 0.019, r = 0.29)
```{r, echo=FALSE, warning=FALSE}

ggplot(AG_DF,aes(x=WM_Az,y=AGscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for working memory", y = "Intermediate Algebra/Coordinate Geometry (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(AG_DF$WM_Az, AG_DF$AGscore, method="pearson")  
```
\newpage

### Working memory speed (no correlation)
```{r, echo=FALSE, warning=FALSE}

ggplot(AG_DF,aes(x=WM_Sz,y=AGscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed speed score for working memory", y = "Intermediate Algebra/Coordinate Geometry (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(AG_DF$WM_Sz, AG_DF$AGscore, method="pearson")    
```
\newpage

### Working memory efficiency (p = 0.016, r = 0.3)
##### Average of normed accuracy and speed scores for working memory.
```{r, echo=FALSE, warning=FALSE}

ggplot(AG_DF,aes(x=WM_EFFICIENCY,y=AGscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Average of normed accuracy and speed scores for working memory", y = "Intermediate Algebra/Coordinate Geometry (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(AG_DF$WM_EFFICIENCY, AG_DF$AGscore, method="pearson")    
```
\newpage

### Spatial perception accuracy (no correlation)
```{r, echo=FALSE, warning=FALSE}

ggplot(AG_DF,aes(x=SPA_Az,y=AGscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for spatial perception", y = "Intermediate Algebra/Coordinate Geometry (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(AG_DF$SPA_Az, AG_DF$AGscore, method="pearson")  
```

\newpage

```{r, echo=FALSE, warning=FALSE, include=FALSE}
#prepare data for level of difficulty analyses

foo <- `70C`[c(1,2,3,4,20),]
subsection <- t(foo)
subsection <- data.frame(subsection)
subsection <- subsection[-1, ] 

colnames(subsection)[1] <- "test"
colnames(subsection)[2] <- "question"
colnames(subsection)[3] <- "section"
colnames(subsection)[4] <- "subsection"
colnames(subsection)[5] <- "difficulty"

questions2 <- t(questions)
subsection <- cbind(subsection, questions2)

write.csv(subsection, "mindprintdifficuty.csv", row.names=TRUE) #save to computer

## Load mindprint difficulty data
q.difficulty <- read.csv("~/Documents/Felicia Zhang/Felicia/Princeton/ConsultingClub/Mindprint/mindprintdifficuty.csv", header=T)

finalDF3 <- cbind(finalDF2, q.difficulty)
```

## Appleseed Suggested Analyses
### EA - abstract reasoning model
```{r, echo=FALSE, warning=FALSE}
EA_model <- lm(EAscore ~ NVR_Az, data=EA_DF)  # accuracy
summary(EA_model)

ggplot(EA_DF,aes(x=NVR_Az,y=EAscore))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for abstract reasoning", y = "Pre-Algebra/Elementary Algebra (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "none")+
  theme(text=element_text(family="Times"))+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)

cor.test(EA_DF$EAscore, EA_DF$NVR_Az, method="pearson")  
```
Elementary algebra is not predicted by abstract reasoning accuracy (p=0.1).

### EA - abstract reasoning broken down by difficulty of questions

Level 1 EA
```{r, echo=FALSE, warning=FALSE}
#level 1 
EA1 <- lm(EA1 ~ NVR_Az, data=finalDF3)  # accuracy
summary(EA1)
```

Level 2 EA
```{r, echo=FALSE, warning=FALSE}
#level 2
EA2 <- lm(EA2 ~ NVR_Az, data=finalDF3)  # accuracy
summary(EA2)
```

Level 3 EA
```{r, echo=FALSE, warning=FALSE}
#level 3
EA3 <- lm(EA3 ~ NVR_Az, data=finalDF3)  # accuracy
summary(EA3)
```

Level 4 EA
```{r, echo=FALSE, warning=FALSE}
#level 4
EA4 <- lm(EA4 ~ NVR_Az, data=finalDF3)  # accuracy
summary(EA4)
```

Level 5 EA
```{r, echo=FALSE, warning=FALSE}
#level 5
EA5 <- lm(EA5 ~ NVR_Az, data=finalDF3)  # accuracy
summary(EA5)
```


```{r, echo=FALSE, warning=FALSE}
#plot 
boo <- read.csv("~/Documents/Felicia Zhang/Felicia/Princeton/ConsultingClub/Mindprint/EAdifficultygraph.csv", header=T)

ggplot(boo,aes(x=NVR_Az,y=EA_score,color=factor(EA_level),fill=factor(EA_level)))+
  geom_point(size=3)+
  theme_bw()+
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
  labs(x = "Normed accuracy score for abstract reasoning", y = "Pre-Algebra/Elementary Algebra (% correct)")+
  theme(plot.title = element_text(face="bold", size=14, hjust=0))+
  theme(axis.title = element_text(face="bold", size=14))+ 
  theme(axis.text.x  = element_text(size=14),axis.text.y  = element_text(size=14))+
  theme(legend.text=element_text(size=14),legend.title=element_text(size=14))+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(legend.position = "bottom")+
  guides(fill=FALSE)+
  theme(text=element_text(family="Times"))+
  scale_color_discrete(name="Difficulty level")+
  scale_y_continuous(labels=percent,limits=c(0,1),breaks=seq(0,1,.1))+
  stat_smooth(method=lm, se=FALSE)
```

\newpage

### GT - abstract reasoning & spatial perception
```{r, echo=FALSE, warning=FALSE}
GT_model <- lm(GTscore ~ NVR_Az + SPA_Az, data=GT_DF)  

summary(GT_model)
```
Plane geometry/trigonometry is predicted by spatial perception accuracy (p=0.034).

\newpage

### GT - abstract reasoning & spatial perception broken down by difficulty of questions

Level 1 GT
```{r, echo=FALSE, warning=FALSE}
#level 1 
GT1 <- lm(GT1 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(GT1)
```

Level 2 GT
```{r, echo=FALSE, warning=FALSE}
#level 2
GT2 <- lm(GT2 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(GT2)
```

Level 3 GT
```{r, echo=FALSE, warning=FALSE}
#level 3
GT3 <- lm(GT3 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(GT3)
```

Level 4 GT
```{r, echo=FALSE, warning=FALSE}
#level 4
GT4 <- lm(GT4 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(GT4)
```

Level 5 GT
```{r, echo=FALSE, warning=FALSE}
#level 5
GT5 <- lm(GT5 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(GT5)
```
The more difficult questions of plane geometry/trigonometry (level 3-5) is predicted by spatial perception accuracy.

\newpage

### AG - abstract reasoning & spatial perception
```{r, echo=FALSE, warning=FALSE}
AG_model <- lm(AGscore ~ NVR_Az + SPA_Az, data=AG_DF)  

summary(AG_model)

```
Algebra/coordinate geometry is not predicted by abstract reasoning or spatial perception.

\newpage
### AG - abstract reasoning & spatial perception broken down by difficulty of questions

Level 1 AG
```{r, echo=FALSE, warning=FALSE}
#level 1 
AG1 <- lm(AG1 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(AG1)
```

Level 2 AG
```{r, echo=FALSE, warning=FALSE}
#level 2
AG2 <- lm(AG2 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(AG2)
```

Level 3 AG
```{r, echo=FALSE, warning=FALSE}
#level 3
AG3 <- lm(AG3 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(AG3)
```

Level 4 AG
```{r, echo=FALSE, warning=FALSE}
#level 4
AG4 <- lm(AG4 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(AG4)
```

Level 5 AG
```{r, echo=FALSE, warning=FALSE}
#level 5
AG5 <- lm(AG5 ~ NVR_Az + SPA_Az, data=finalDF3)  # accuracy
summary(AG5)
```
Overall algebra/coordinate geometry is not predicted by abstract reasoning or spatial perception. But level 1 algebra/coordinate geometry is predicted by spatial perception.

\newpage

### AG - abstract reasoning & spatial perception & flexible thinking
```{r, echo=FALSE, warning=FALSE}
AG_model2 <- lm(AGscore ~ NVR_Az + SPA_Az + ABF_Az, data=AG_DF)  

summary(AG_model2)
```
Algebra/coordinate geometry is not predicted by abstract reasoning, spatial perception or flexible thinking. 

\newpage

### AG - abstract reasoning & spatial perception & flexible thinking broken down by difficulty of questions

Level 1 AG
```{r, echo=FALSE, warning=FALSE}
#level 1 
AG1 <- lm(AG1 ~ NVR_Az + SPA_Az + ABF_Az, data=finalDF3)  # accuracy
summary(AG1)
```

Level 2 AG
```{r, echo=FALSE, warning=FALSE}
#level 2
AG2 <- lm(AG2 ~ NVR_Az + SPA_Az + ABF_Az, data=finalDF3)  # accuracy
summary(AG2)
```

Level 3 AG
```{r, echo=FALSE, warning=FALSE}
#level 3
AG3 <- lm(AG3 ~ NVR_Az + SPA_Az + ABF_Az, data=finalDF3)  # accuracy
summary(AG3)
```

Level 4 AG
```{r, echo=FALSE, warning=FALSE}
#level 4
AG4 <- lm(AG4 ~ NVR_Az + SPA_Az + ABF_Az, data=finalDF3)  # accuracy
summary(AG4)
```

Level 5 AG
```{r, echo=FALSE, warning=FALSE}
#level 5
AG5 <- lm(AG5 ~ NVR_Az + SPA_Az + ABF_Az, data=finalDF3)  # accuracy
summary(AG5)
```
Algebra/coordinate geometry is not predicted by abstract reasoning, spatial perception or flexible thinking but level 1 algebra/coordinate geometry is predicted by spatial perception.

\newpage

## Summary

1. Overall math score is predicted by spatial perception and WM efficiency.

2. Elementary algebra score is predicted by spatial perception. It is not predicted by abstract reasoning even when broken down by question difficulty.

3. Plane geometry/trigonometry score is predicted by spatial perception accuracy. Specifically, the more difficult questions of plane geometry/trigonometry (level 3-5) is predicted by spatial perception accuracy.

4. Intermediate algebra/coordinate geometry is predicted by WM efficiency. But level 1 intermediate algebra/coordinate geometry is predicted by spatial perception.
